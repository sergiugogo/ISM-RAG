# Example environment configuration for production deployment

# Vector Database Configuration
VECTOR_DB_PROVIDER=qdrant  # chromadb, pinecone, weaviate, qdrant
VECTOR_DB_API_KEY=your-api-key-here
VECTOR_DB_HOST=https://your-qdrant-instance.cloud
VECTOR_DB_INDEX=remax_documents
VECTOR_DB_PATH=../chroma_store  # For local ChromaDB

# Embedding Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_BATCH_SIZE=32
EMBEDDING_DEVICE=cuda  # cpu, cuda, mps

# LLM Configuration
LLM_PROVIDER=ollama  # ollama, openai, anthropic, azure
MODEL_NAME=gpt-oss:120b
OLLAMA_API_KEY=your-ollama-api-key
LLM_HOST=https://ollama.com
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=1000

# Processing Configuration
CHUNK_SIZE=800
CHUNK_OVERLAP=100
MAX_WORKERS=8
BATCH_INSERT_SIZE=100
ENABLE_OCR=true

# Query Configuration
TOP_K_RESULTS=5

# Storage Configuration
UPLOAD_DIR=uploads
PROCESSED_FILES_PATH=processed_files.json
