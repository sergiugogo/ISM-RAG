Perfect ğŸ‘ â€” Ã®È›i las mai jos un **README.md complet**, pregÄƒtit pentru GitHub È™i portofoliul ISM.
Totul e formatat frumos, cu emoji-uri, badge-uri È™i secÈ›iuni clare.
Ãl poÈ›i copia direct Ã®ntr-un fiÈ™ier nou `README.md` din root-ul proiectului.

---

```markdown
# ğŸ“˜ SmartDoc QA â€” AI Document Chat (RAG System)
> A project by **Innovative Software & Models SRL (ISM)**

[![Made with FastAPI](https://img.shields.io/badge/Made%20with-FastAPI-109989.svg?style=flat-square&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Made with Streamlit](https://img.shields.io/badge/UI-Streamlit-FF4B4B.svg?style=flat-square&logo=streamlit)](https://streamlit.io/)
[![Vector DB](https://img.shields.io/badge/DB-ChromaDB-00C2CB.svg?style=flat-square&logo=database)](https://www.trychroma.com/)
[![AI Model](https://img.shields.io/badge/AI-Ollama%20Cloud-blue?logo=openai)](https://ollama.com)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

---

## ğŸ§  Overview

**SmartDoc QA** is an AI-powered **Retrieval-Augmented Generation (RAG)** system  
that allows you to **upload any PDF document** and **ask natural-language questions** about its content.

It combines:
- ğŸ” **ChromaDB** for vector-based semantic search  
- ğŸ¤– **Ollama Cloud LLMs** (GPT-OSS, Mistral, etc.) for contextual answers  
- ğŸ§¾ **docTR OCR** for scanned documents (no need for Tesseract or Poppler)  
- âš™ï¸ **FastAPI + Streamlit** for a modern backend/frontend stack  

This project was built by **ISM (Innovative Software & Models SRL)** as a portfolio demo  
to showcase production-ready AI capabilities.

---

## âš™ï¸ Features

| Feature | Description |
|----------|-------------|
| ğŸ“„ **PDF Upload** | Upload any PDF â€” text-based or scanned |
| ğŸ§  **RAG Architecture** | Combines retrieval (ChromaDB) + generation (LLM) |
| ğŸ§¾ **OCR Integration** | Extracts text from images using docTR |
| âš¡ **One-Time Processing** | OCR & embeddings are generated once per file |
| ğŸ§± **Persistent Vector Store** | Uses ChromaDB with automatic on-disk persistence |
| ğŸš¦ **Guardrails** | Detects missing context and prevents hallucinations |
| ğŸ’¬ **Interactive UI** | Chat-style interface built with Streamlit |
| â˜ï¸ **Cloud / Local LLMs** | Compatible with Ollama Cloud or local models |

---

## ğŸ§© Tech Stack

**Backend:**  
- FastAPI  
- ChromaDB  
- SentenceTransformers  
- docTR (OCR)  
- Ollama Cloud API  

**Frontend:**  
- Streamlit  
- Requests  
- Tailwind-style layout  

---

## ğŸ—‚ï¸ Project Structure

```

RAG/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py               # FastAPI routes (upload, ask)
â”‚   â”œâ”€â”€ rag_engine.py         # Core RAG engine (search, generate)
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py     # Text extraction + OCR (docTR)
â”‚   â”‚   â””â”€â”€ splitter.py       # Chunking logic
â”‚   â”œâ”€â”€ uploads/              # Uploaded PDF files
â”‚   â”œâ”€â”€ chroma_store/         # Persistent ChromaDB index
â”‚   â””â”€â”€ processed_files.json  # Cache of processed files
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                # Streamlit UI
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md                 # Project documentation

````

---

## ğŸš€ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<sergiugogo>/ISM-RAG.git
cd ISM-RAG
````

### 2ï¸âƒ£ Create a virtual environment

```bash
python -m venv .venv
.venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r backend/requirements.txt
pip install -r frontend/requirements.txt
```

### 4ï¸âƒ£ Configure environment

Create a file `backend/.env`:

```bash
OLLAMA_API_KEY=your_ollama_api_key_here
MODEL_NAME=gpt-oss:20b
```

### 5ï¸âƒ£ Run backend

```bash
cd backend
uvicorn main:app --reload
```

### 6ï¸âƒ£ Run frontend

```bash
cd ../frontend
streamlit run app.py
```

Then open ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

---

## ğŸ’¬ Usage

1. Upload a PDF in the Streamlit interface.
2. The system will automatically:

   * extract text (OCR if needed)
   * create embeddings
   * store them in ChromaDB
3. Ask any question about the document:

   * â€œCare este numele persoanei din contract?â€
   * â€œCe spune articolul 3 despre durata contractului?â€
4. Get an instant, AI-generated answer.

---

## ğŸ§¾ Example Output

**Upload response:**

```json
{
  "message": "PDF procesat È™i adÄƒugat Ã®n baza de date.",
  "chunks": 12
}
```

**Ask response:**

```json
{
  "question": "Care este subsemnatul din aceastÄƒ cerere?",
  "answer": "Subsemnatul din aceastÄƒ cerere este MozeÈ™ Ioan Andrei.",
  "context": "..."
}
```

---

## ğŸ§± Future Improvements

* [ ] Add multi-document RAG (cross-file context)
* [ ] Add conversation memory (chat history)
* [ ] Add streaming answers (real-time output)
* [ ] Add authentication for multiple users
* [ ] Deploy online via Render / Hugging Face Spaces

---

## ğŸ¢ About ISM

> **Innovative Software & Models SRL (ISM)**
> Empowering businesses with intelligent automation and AI.

ğŸ“ Cluj-Napoca, RomÃ¢nia
ğŸŒ Website: *coming soon*
ğŸ“§ Contact: *[contact@ism-ai.ro](mailto:mogosansergiu39@gmail.com)*

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.

---

**Built with â¤ï¸ by Mogosan Sergiu-Ionut @ ISM**
*AI Developer & Founder â€“ Innovative Software & Models SRL*

```